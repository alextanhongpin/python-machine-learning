{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heated-kernel",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alextanhongpin/python-machine-learning/blob/master/08_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amazing-tiffany",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "static-slide",
    "outputId": "e3471dfd-b951-49f9-bec4-ca2e6fe1624f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  48.5M      0  0:00:01  0:00:01 --:--:-- 48.5M\n"
     ]
    }
   ],
   "source": [
    "# https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "!curl https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -o aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nutritional-major",
   "metadata": {
    "id": "impossible-glass"
   },
   "outputs": [],
   "source": [
    "!tar -zxf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "limiting-lebanon",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grave-migration",
    "outputId": "7e296b38-5dd0-4152-d07a-97de0a09f460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyprind in /usr/local/lib/python3.7/dist-packages (2.11.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "north-durham",
   "metadata": {
    "id": "canadian-broadcasting"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "material-provincial",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "included-tonight",
    "outputId": "75afe73b-4ea3-40bc-8a64-6df10e60ef64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:10\n"
     ]
    }
   ],
   "source": [
    "basepath = \"aclImdb\"\n",
    "\n",
    "labels = {\"pos\": 1, \"neg\": 0}\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for s in (\"test\", \"train\"):\n",
    "    for l in (\"pos\", \"neg\"):\n",
    "        path = os.path.join(basepath, s, l)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path, file), \"r\", encoding=\"utf-8\") as infile:\n",
    "                txt = infile.read()\n",
    "            df = df.append([[txt, labels[l]]], ignore_index=True)\n",
    "            pbar.update()\n",
    "df.columns = [\"review\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transparent-walter",
   "metadata": {
    "id": "seasonal-threat"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv(\"movie_data.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "measured-advance",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "bigger-toolbox",
    "outputId": "34f902d4-562e-4e05-9dff-d5de1868bb27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"movie_data.csv\", encoding=\"utf-8\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "retained-belly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "reasonable-delight",
    "outputId": "f87ce1e2-1960-4805-b216-1b774932e50a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 1, 1, 1],\n",
       "       [1, 2, 1, 1, 1, 2, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "docs = np.array(\n",
    "    [\n",
    "        \"The sun is shining\",\n",
    "        \"The weather is sweet\",\n",
    "        \"The sun is shining and the weather is sweet\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "bag = count.fit_transform(docs)\n",
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indoor-dakota",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "protecting-evening",
    "outputId": "65a1dc0b-b4db-4792-ec2f-b1c039a3b24a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 5, 'sun': 3, 'is': 1, 'shining': 2, 'weather': 6, 'sweet': 4, 'and': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "skilled-recruitment",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apparent-shell",
    "outputId": "96501d77-ded6-4f43-fe18-4265289cbb53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.43, 0.56, 0.56, 0.  , 0.43, 0.  ],\n",
       "       [0.  , 0.43, 0.  , 0.  , 0.56, 0.43, 0.56],\n",
       "       [0.4 , 0.48, 0.31, 0.31, 0.31, 0.48, 0.31]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, norm=\"l2\", smooth_idf=True)\n",
    "np.set_printoptions(precision=2)\n",
    "tfidf.fit_transform(count.fit_transform(docs)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loaded-elite",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "charming-tuesday",
    "outputId": "bb2c2f73-c0a5-42ae-c3ad-24e47468b55c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to Star Cinema!! Way to go, Jericho and Claudine!!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, \"review\"][-50:]  # Print last 50 characters from the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bizarre-borough",
   "metadata": {
    "id": "extensive-webmaster"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
    "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
    "    text = re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gentle-pointer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "directed-assessment",
    "outputId": "4549999c-6114-411f-a546-fe34f04d8175"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test :) :( :)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(\"</a>This :) is :( a test :-)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "latin-punishment",
   "metadata": {
    "id": "strange-rochester"
   },
   "outputs": [],
   "source": [
    "df.review = df.review.apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "imperial-constitutional",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plastic-karma",
    "outputId": "fc6ae085-ffef-445b-fe2c-218afbaf88c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "tokenizer(\"runners like running and thus they run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sophisticated-treasure",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "single-charger",
    "outputId": "061c8a09-b5b0-4936-82bb-8205a0e5cb3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "\n",
    "tokenizer_porter(\"runners like running and thus they run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "blank-contribution",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "composed-toilet",
    "outputId": "50d097b9-0609-40e9-ce05-afc0793b231c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alextanhongpin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prerequisite-commitment",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "subjective-mattress",
    "outputId": "ed793f87-cefc-46c4-a3a9-54cb8aa360b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'runnign', 'run', 'lot']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words(\"english\")\n",
    "[\n",
    "    w\n",
    "    for w in tokenizer_porter(\"a runner likes runnign and runs a lot\")[-10:]\n",
    "    if w not in stop\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-morocco",
   "metadata": {
    "id": "characteristic-uniform"
   },
   "source": [
    "# Training a logistic regression model for document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reliable-merchandise",
   "metadata": {
    "id": "active-flood"
   },
   "outputs": [],
   "source": [
    "X_train = df.loc[:25000, \"review\"].values\n",
    "y_train = df.loc[:25000, \"sentiment\"].values\n",
    "\n",
    "X_test = df.loc[25000:, \"review\"].values\n",
    "y_test = df.loc[25000:, \"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-rebound",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WE5Z2vg_spva",
    "outputId": "e8efb36c-7a01-4762-c080-b382c60c0315"
   },
   "outputs": [],
   "source": [
    "!pip install tune_sklearn 'ray[tune]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "proprietary-horizontal",
   "metadata": {
    "id": "VBIjDt_4sv1C"
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/5x-faster-scikit-learn-parameter-tuning-in-5-lines-of-code-be6bdd21833c\n",
    "from tune_sklearn import TuneGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-israel",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tutorial-testimony",
    "outputId": "0950712e-22ef-4d4b-cb0f-541d887008da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/ray/tune/tune.py:375: UserWarning: The `loggers` argument is deprecated. Please pass the respective `LoggerCallback` classes to the `callbacks` argument instead. See https://docs.ray.io/en/latest/tune/api_docs/logging.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:15 (running for 00:00:00.14)<br>Memory usage on this node: 5.5/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 1/48 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_PipelineTrainable pid=88354)\u001b[0m /usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', \"it'\", 'onc', 'onli', 'ourselv', \"she'\", \"should'v\", 'themselv', 'thi', 'veri', 'wa', 'whi', \"you'r\", \"you'v\", 'yourselv'] not in stop_words.\n",
      "\u001b[2m\u001b[36m(_PipelineTrainable pid=88354)\u001b[0m   warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:20 (running for 00:00:05.15)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:25 (running for 00:00:10.18)<br>Memory usage on this node: 5.6/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:31 (running for 00:00:15.73)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:36 (running for 00:00:20.77)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:41 (running for 00:00:25.80)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:46 (running for 00:00:30.84)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da614bee reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:51 (running for 00:00:35.95)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725253189362128<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da614bee with average_test_score=0.8725253189362128 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x11f295430>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da9c63c8 reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:50:56 (running for 00:00:41.02)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f295ee0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:01 (running for 00:00:46.11)<br>Memory usage on this node: 5.6/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f295ee0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:06 (running for 00:00:51.15)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f295ee0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:11 (running for 00:00:56.18)<br>Memory usage on this node: 5.8/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f295ee0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da614bee reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:17 (running for 00:01:01.85)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f295ee0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:22 (running for 00:01:06.89)<br>Memory usage on this node: 5.6/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f295ee0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da9c63c8 reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:28 (running for 00:01:12.88)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f603f70>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:33 (running for 00:01:17.96)<br>Memory usage on this node: 5.6/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f603f70>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:38 (running for 00:01:23.00)<br>Memory usage on this node: 5.8/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f603f70>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da614bee reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:44 (running for 00:01:28.95)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f603f70>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:49 (running for 00:01:34.00)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f603f70>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:54 (running for 00:01:39.02)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f603f70>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:51:59 (running for 00:01:44.10)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f603f70>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da9c63c8 reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:05 (running for 00:01:50.00)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x165e06af0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:10 (running for 00:01:55.06)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: None | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x165e06af0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da614bee reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:15 (running for 00:02:00.24)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725253189362128 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x165e06af0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:21 (running for 00:02:05.38)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725253189362128 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x165e06af0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:26 (running for 00:02:10.44)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725253189362128 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x165e06af0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:31 (running for 00:02:15.47)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725253189362128 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x165e06af0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da9c63c8 reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:36 (running for 00:02:20.88)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bdc0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da614bee reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:41 (running for 00:02:26.17)<br>Memory usage on this node: 5.6/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bdc0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:46 (running for 00:02:31.28)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bdc0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:52 (running for 00:02:36.32)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bdc0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:52:57 (running for 00:02:41.39)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bdc0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:02 (running for 00:02:46.43)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bdc0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:07 (running for 00:02:51.49)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bdc0>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da614bee reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n",
      "Trial _PipelineTrainable_da9c63c8 reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:12 (running for 00:02:56.67)<br>Memory usage on this node: 5.6/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bb80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:17 (running for 00:03:01.84)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bb80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:22 (running for 00:03:06.93)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bb80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:27 (running for 00:03:12.01)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bb80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:32 (running for 00:03:17.05)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bb80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:37 (running for 00:03:22.16)<br>Memory usage on this node: 5.8/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bb80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da614bee reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:43 (running for 00:03:28.00)<br>Memory usage on this node: 5.8/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f68bb80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da9c63c8 reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:49 (running for 00:03:33.79)<br>Memory usage on this node: 5.8/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f688b80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:54 (running for 00:03:38.87)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f688b80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_PipelineTrainable pid=88354)\u001b[0m /usr/local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', \"it'\", 'onc', 'onli', 'ourselv', \"she'\", \"should'v\", 'themselv', 'thi', 'veri', 'wa', 'whi', \"you'r\", \"you'v\", 'yourselv'] not in stop_words.\n",
      "\u001b[2m\u001b[36m(_PipelineTrainable pid=88354)\u001b[0m   warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:53:59 (running for 00:03:43.93)<br>Memory usage on this node: 5.6/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f688b80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:54:04 (running for 00:03:48.97)<br>Memory usage on this node: 5.7/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f688b80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial _PipelineTrainable_da614bee reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x105e0b9d0>}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-13 00:54:10 (running for 00:03:54.51)<br>Memory usage on this node: 5.8/8.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 4.000: 0.8725852289542092 | Iter 1.000: 0.8725852289542092<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.49 GiB heap, 0.0/1.25 GiB objects<br>Current best trial: da9c63c8 with average_test_score=0.872605198960208 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000024000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000025000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000026000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000027000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000028000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000029000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000002a000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x11f688b80>}<br>Result logdir: /Users/alextanhongpin/ray_results/_PipelineTrainable_2022-02-13_00-50-15<br>Number of trials: 5/48 (1 PENDING, 4 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
    "param_grid = [\n",
    "    {\n",
    "        \"vect__ngram_range\": [(1, 1)],\n",
    "        \"vect__stop_words\": [stop, None],\n",
    "        \"vect__tokenizer\": [tokenizer, tokenizer_porter],\n",
    "        \"clf__penalty\": [\"l1\", \"l2\"],\n",
    "        \"clf__C\": [1.0, 10.0, 100.0],\n",
    "    },\n",
    "    {\n",
    "        \"vect__ngram_range\": [(1, 1)],\n",
    "        \"vect__stop_words\": [stop, None],\n",
    "        \"vect__tokenizer\": [tokenizer, tokenizer_porter],\n",
    "        \"vect__use_idf\": [False],\n",
    "        \"vect__norm\": [None],\n",
    "        \"clf__penalty\": [\"l1\", \"l2\"],\n",
    "        \"clf__C\": [1.0, 10.0, 100.0],\n",
    "    },\n",
    "]\n",
    "\n",
    "lr_tfidf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", tfidf),\n",
    "        (\n",
    "            \"clf\",\n",
    "            LogisticRegression(\n",
    "                random_state=0, dual=False, solver=\"liblinear\", max_iter=1000\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# gs_lr_tfidf = GridSearchCV(\n",
    "gs_lr_tfidf = TuneGridSearchCV(\n",
    "    lr_tfidf,\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    # Two new parameters.\n",
    "    early_stopping=True,\n",
    "    max_iters=10,\n",
    ")\n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-pattern",
   "metadata": {
    "id": "found-adjustment"
   },
   "outputs": [],
   "source": [
    "print(f\"Best parameter set: {gs_lr_tfidf.best_params_}\")\n",
    "print(f\"CV Accuracy: {gs_lr_tfidf.best_score_:.3f}\")\n",
    "\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print(\"Test Accuracy: {0:.3f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-failing",
   "metadata": {
    "id": "built-bargain"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "if not os.path.isfile(\"movie_data.csv\"):\n",
    "    if not os.path.isfile(\"movie_data.csv.zip\"):\n",
    "        print(\n",
    "            \"Please place a copy of the movie_data.csv.gz\"\n",
    "            \"in this directory. You can obtain it by\"\n",
    "            \"a) executing the code in the beginning of this\"\n",
    "            \"notebook or b) by downloading it from GitHub:\"\n",
    "            \"https://github.com/rasbt/python-machine-learning-\"\n",
    "            \"book-2nd-edition/blob/master/code/ch08/movie_data.csv.gz\"\n",
    "        )\n",
    "    else:\n",
    "        with zipfile.ZipFile(\"movie_data.csv.zip\", \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-difference",
   "metadata": {
    "id": "removable-trainer"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
    "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
    "    text = re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-acting",
   "metadata": {
    "id": "associate-asset"
   },
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as csv:\n",
    "        next(csv)  # Skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-swing",
   "metadata": {
    "id": "separate-distribution"
   },
   "outputs": [],
   "source": [
    "next(stream_docs(path=\"movie_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-candy",
   "metadata": {
    "id": "experimental-integration"
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mobile",
   "metadata": {
    "id": "attempted-nepal"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "vect = HashingVectorizer(\n",
    "    decode_error=\"ignore\", n_features=2 ** 21, preprocessor=None, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "clf = SGDClassifier(loss=\"log\", random_state=1, max_iter=1)\n",
    "doc_stream = stream_docs(path=\"movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-london",
   "metadata": {
    "id": "selected-bernard"
   },
   "outputs": [],
   "source": [
    "import pyprind\n",
    "\n",
    "pbar = pyprind.ProgBar(45)\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-immune",
   "metadata": {
    "id": "classified-track"
   },
   "outputs": [],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print(\"Accuracy: {0:.3f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-turtle",
   "metadata": {
    "id": "critical-steam"
   },
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-forth",
   "metadata": {
    "id": "statutory-messenger"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words=\"english\", max_df=0.1, max_features=5000)\n",
    "X = count.fit_transform(df[\"review\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-formation",
   "metadata": {
    "id": "affiliated-stake"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=10, random_state=123, learning_method=\"batch\"\n",
    ")\n",
    "X_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-drove",
   "metadata": {
    "id": "split-visit"
   },
   "outputs": [],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-swiss",
   "metadata": {
    "id": "difficult-albania"
   },
   "outputs": [],
   "source": [
    "n_top_words = 5\n",
    "feature_names = count.get_feature_names()\n",
    "\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic {0}\".format(topic_idx + 1))\n",
    "    print(\n",
    "        \" \".join(\n",
    "            [feature_names[i] for i in topic.argsort()[: -n_top_words - 1 : -1]]\n",
    "        )  # Sort in reverse orders\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-advice",
   "metadata": {
    "id": "cardiac-preference"
   },
   "outputs": [],
   "source": [
    "horror = X_topics[:, 5].argsort()[::-1]\n",
    "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
    "    print(\"Horror movie #{0}\".format(iter_idx + 1))\n",
    "    print(df[\"review\"][movie_idx][:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-lesbian",
   "metadata": {
    "id": "temporal-jordan"
   },
   "source": [
    "# Serializing fitted scikit-learn estimators\n",
    "\n",
    "- training machine learning is computationally expensive\n",
    "- pickled allow us to serialize/deserialize Python object structures to compact bytecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-wrestling",
   "metadata": {
    "id": "casual-appliance"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "dest = os.path.join(\"movieclassifier\", \"pkl_objects\")\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "\n",
    "pickle.dump(stop, open(os.path.join(dest, \"stopwords.pkl\"), \"wb\"), protocol=4)\n",
    "pickle.dump(clf, open(os.path.join(dest, \"classifier.pkl\"), \"wb\"), protocol=4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "08_sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alextanhongpin/python-machine-learning/blob/master/08_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "static-slide",
      "metadata": {
        "id": "static-slide",
        "outputId": "a522dd05-e6ee-4f5c-a829-7c20f40d19a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  22.1M      0  0:00:03  0:00:03 --:--:-- 22.1M\n"
          ]
        }
      ],
      "source": [
        "# https://ai.stanford.edu/~amaas/data/sentiment/\n",
        "!curl https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -o aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "impossible-glass",
      "metadata": {
        "id": "impossible-glass"
      },
      "outputs": [],
      "source": [
        "!tar -zxf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "grave-migration",
      "metadata": {
        "id": "grave-migration",
        "outputId": "eaf34dd9-3c0a-49cd-9f49-d676a7a4b1ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyprind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "canadian-broadcasting",
      "metadata": {
        "id": "canadian-broadcasting"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import pyprind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "included-tonight",
      "metadata": {
        "id": "included-tonight",
        "outputId": "82d543a3-f8bb-4517-feca-f8983c8d6c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:22\n"
          ]
        }
      ],
      "source": [
        "basepath = \"aclImdb\"\n",
        "\n",
        "labels = {\"pos\": 1, \"neg\": 0}\n",
        "pbar = pyprind.ProgBar(50000)\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for s in (\"test\", \"train\"):\n",
        "    for l in (\"pos\", \"neg\"):\n",
        "        path = os.path.join(basepath, s, l)\n",
        "        for file in os.listdir(path):\n",
        "            with open(os.path.join(path, file), \"r\", encoding=\"utf-8\") as infile:\n",
        "                txt = infile.read()\n",
        "            df = df.append([[txt, labels[l]]], ignore_index=True)\n",
        "            pbar.update()\n",
        "df.columns = [\"review\", \"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "seasonal-threat",
      "metadata": {
        "id": "seasonal-threat"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv(\"movie_data.csv\", index=False, encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bigger-toolbox",
      "metadata": {
        "id": "bigger-toolbox",
        "outputId": "b1209e85-46a3-466c-bb50-369125ac97a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-65a07f80-aba3-4de7-b77c-8441499893f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is a well directed Columbo episode, with ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is a movie with an excellent concept for ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is possibly the worst version of the play...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65a07f80-aba3-4de7-b77c-8441499893f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65a07f80-aba3-4de7-b77c-8441499893f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65a07f80-aba3-4de7-b77c-8441499893f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  This is a well directed Columbo episode, with ...          1\n",
              "1  This is a movie with an excellent concept for ...          0\n",
              "2  This is possibly the worst version of the play...          0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df = pd.read_csv(\"movie_data.csv\", encoding=\"utf-8\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "reasonable-delight",
      "metadata": {
        "id": "reasonable-delight",
        "outputId": "72aba545-8fd8-447f-ccbe-00a4e7a0beeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 1, 1, 1],\n",
              "       [1, 2, 1, 1, 1, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "docs = np.array(\n",
        "    [\n",
        "        \"The sun is shining\",\n",
        "        \"The weather is sweet\",\n",
        "        \"The sun is shining and the weather is sweet\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "bag = count.fit_transform(docs)\n",
        "bag.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "protecting-evening",
      "metadata": {
        "id": "protecting-evening",
        "outputId": "58ed7c90-6b2b-4650-e00c-b51558563f0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 0, 'is': 1, 'shining': 2, 'sun': 3, 'sweet': 4, 'the': 5, 'weather': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "count.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "apparent-shell",
      "metadata": {
        "id": "apparent-shell",
        "outputId": "9fa6dc88-c652-4d25-ecf8-6d7670512f49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.43, 0.56, 0.56, 0.  , 0.43, 0.  ],\n",
              "       [0.  , 0.43, 0.  , 0.  , 0.56, 0.43, 0.56],\n",
              "       [0.4 , 0.48, 0.31, 0.31, 0.31, 0.48, 0.31]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf = TfidfTransformer(use_idf=True, norm=\"l2\", smooth_idf=True)\n",
        "np.set_printoptions(precision=2)\n",
        "tfidf.fit_transform(count.fit_transform(docs)).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "charming-tuesday",
      "metadata": {
        "id": "charming-tuesday",
        "outputId": "3d8bcee8-da10-4759-9c1c-a48d09c6dfeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' with a better thought out script.<br /><br />7/10'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.loc[0, \"review\"][-50:]  # Print last 50 characters from the review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "extensive-webmaster",
      "metadata": {
        "id": "extensive-webmaster"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def preprocessor(text):\n",
        "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
        "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
        "    text = re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "directed-assessment",
      "metadata": {
        "id": "directed-assessment",
        "outputId": "410394cd-ce7f-49a4-89d8-827698eebec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is a test :) :( :)'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "preprocessor(\"</a>This :) is :( a test :-)!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "strange-rochester",
      "metadata": {
        "id": "strange-rochester"
      },
      "outputs": [],
      "source": [
        "df.review = df.review.apply(preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "plastic-karma",
      "metadata": {
        "id": "plastic-karma",
        "outputId": "ce05c764-5413-4dcd-df98-74c3b15dd1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "tokenizer(\"runners like running and thus they run\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "single-charger",
      "metadata": {
        "id": "single-charger",
        "outputId": "e2c45ef3-5bb8-4173-e8b9-67f863545d27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "\n",
        "\n",
        "tokenizer_porter(\"runners like running and thus they run\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "composed-toilet",
      "metadata": {
        "id": "composed-toilet",
        "outputId": "2ca04d0b-b0db-4294-8af1-d473eb5502a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "subjective-mattress",
      "metadata": {
        "id": "subjective-mattress",
        "outputId": "84a47c27-e3fc-44ec-f565-39d087c24904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'runnign', 'run', 'lot']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "[\n",
        "    w\n",
        "    for w in tokenizer_porter(\"a runner likes runnign and runs a lot\")[-10:]\n",
        "    if w not in stop\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "characteristic-uniform",
      "metadata": {
        "id": "characteristic-uniform"
      },
      "source": [
        "# Training a logistic regression model for document classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "active-flood",
      "metadata": {
        "id": "active-flood"
      },
      "outputs": [],
      "source": [
        "X_train = df.loc[:25000, \"review\"].values\n",
        "y_train = df.loc[:25000, \"sentiment\"].values\n",
        "\n",
        "X_test = df.loc[25000:, \"review\"].values\n",
        "y_test = df.loc[25000:, \"sentiment\"].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tune_sklearn"
      ],
      "metadata": {
        "id": "WE5Z2vg_spva",
        "outputId": "96daa104-c5a4-4de7-c90c-aa147cd328ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WE5Z2vg_spva",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tune_sklearn\n",
            "  Downloading tune_sklearn-0.4.1-py3-none-any.whl (40 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████▏                       | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 30 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from tune_sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from tune_sklearn) (1.19.5)\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-1.10.0-cp37-cp37m-manylinux2014_x86_64.whl (59.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tune_sklearn) (1.4.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (1.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (21.4.0)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.1.3-py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 69.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (4.3.3)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (1.43.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (3.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (1.3.5)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 77.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (0.8.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray[tune]->tune_sklearn) (1.15.0)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]->tune_sklearn) (21.3)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]->tune_sklearn) (4.10.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]->tune_sklearn) (1.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]->tune_sklearn) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]->tune_sklearn) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]->tune_sklearn) (3.0.7)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]->tune_sklearn) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]->tune_sklearn) (5.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]->tune_sklearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]->tune_sklearn) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune_sklearn) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune_sklearn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune_sklearn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune_sklearn) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tune_sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tune_sklearn) (3.1.0)\n",
            "Installing collected packages: deprecated, redis, tensorboardX, ray, tune-sklearn\n",
            "Successfully installed deprecated-1.2.13 ray-1.10.0 redis-4.1.3 tensorboardX-2.4.1 tune-sklearn-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/5x-faster-scikit-learn-parameter-tuning-in-5-lines-of-code-be6bdd21833c\n",
        "from tune_sklearn import TuneSearchCV"
      ],
      "metadata": {
        "id": "VBIjDt_4sv1C"
      },
      "id": "VBIjDt_4sv1C",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tutorial-testimony",
      "metadata": {
        "id": "tutorial-testimony",
        "outputId": "284f3349-39e4-465e-f297-0260cadbb66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tune_sklearn/tune_basesearch.py:433: UserWarning: early_stopping is enabled but max_iters = 1. To enable partial training, set max_iters > 1.\n",
            "  category=UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/ray/tune/tune.py:376: UserWarning: The `loggers` argument is deprecated. Please pass the respective `LoggerCallback` classes to the `callbacks` argument instead. See https://docs.ray.io/en/latest/tune/api_docs/logging.html\n",
            "  \"The `loggers` argument is deprecated. Please pass the respective \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:13:33 (running for 00:00:01.01)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: None<br>Resources requested: 1.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 1/10 (1 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:13:37 (running for 00:00:05.26)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 3/10 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:13:42 (running for 00:00:10.28)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 3/10 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:13:48 (running for 00:00:16.12)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 3/10 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:13:53 (running for 00:00:21.14)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 3/10 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial _PipelineTrainable_b8f4bed2 reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f3f87dcc170>, 'clf__penalty': 'l1', 'clf__C': 1.0}. This trial completed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:13:58 (running for 00:00:26.15)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8730850709858029<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b8f4bed2 with average_test_score=0.8730850709858029 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f3f4b08bef0>, 'clf__penalty': 'l1', 'clf__C': 1.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 4/10 (1 PENDING, 2 RUNNING, 1 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:03 (running for 00:00:31.19)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8730850709858029<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b8f4bed2 with average_test_score=0.8730850709858029 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f3f4b08bef0>, 'clf__penalty': 'l1', 'clf__C': 1.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 4/10 (1 PENDING, 2 RUNNING, 1 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial _PipelineTrainable_b98f0d84 reported average_test_score=0.89 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f87dcc170>, 'clf__penalty': 'l2', 'clf__C': 10.0}. This trial completed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:08 (running for 00:00:36.49)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 1.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 4/10 (1 PENDING, 1 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:13 (running for 00:00:41.55)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 5/10 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:18 (running for 00:00:46.59)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 5/10 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:23 (running for 00:00:51.62)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 5/10 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:28 (running for 00:00:56.65)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 5/10 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:33 (running for 00:01:01.68)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 5/10 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:38 (running for 00:01:06.71)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 5/10 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:43 (running for 00:01:11.74)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 5/10 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:48 (running for 00:01:16.76)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.88937450109978<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 5/10 (1 PENDING, 2 RUNNING, 2 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial _PipelineTrainable_c704e330 reported average_test_score=0.87 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f3f87dcc170>, 'vect__use_idf': False, 'vect__norm': None, 'clf__penalty': 'l2', 'clf__C': 100.0}. This trial completed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:53 (running for 00:01:21.78)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:14:59 (running for 00:01:26.88)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:15:04 (running for 00:01:32.35)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:15:09 (running for 00:01:37.39)<br>Memory usage on this node: 2.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:15:14 (running for 00:01:42.41)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:15:19 (running for 00:01:47.44)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:15:24 (running for 00:01:52.47)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:15:29 (running for 00:01:57.49)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:15:34 (running for 00:02:02.51)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 1.000: 0.8839446910617876<br>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/6.55 GiB heap, 0.0/3.27 GiB objects (0.0/1.0 accelerator_type:T4)<br>Current best trial: b98f0d84 with average_test_score=0.8948043111377725 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 1, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000008000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000009000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff010000000a000000)], 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x7f3f4b0bc7a0>, 'clf__penalty': 'l2', 'clf__C': 10.0}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-13-32<br>Number of trials: 6/10 (1 PENDING, 2 RUNNING, 3 TERMINATED)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
        "param_grid = [\n",
        "    {\n",
        "        \"vect__ngram_range\": [(1, 1)],\n",
        "        \"vect__stop_words\": [stop, None],\n",
        "        \"vect__tokenizer\": [tokenizer, tokenizer_porter],\n",
        "        \"clf__penalty\": [\"l1\", \"l2\"],\n",
        "        \"clf__C\": [1.0, 10.0, 100.0],\n",
        "    },\n",
        "    {\n",
        "        \"vect__ngram_range\": [(1, 1)],\n",
        "        \"vect__stop_words\": [stop, None],\n",
        "        \"vect__tokenizer\": [tokenizer, tokenizer_porter],\n",
        "        \"vect__use_idf\": [False],\n",
        "        \"vect__norm\": [None],\n",
        "        \"clf__penalty\": [\"l1\", \"l2\"],\n",
        "        \"clf__C\": [1.0, 10.0, 100.0],\n",
        "    },\n",
        "]\n",
        "\n",
        "lr_tfidf = Pipeline(\n",
        "    [(\"vect\", tfidf), (\"clf\", LogisticRegression(random_state=0, solver=\"liblinear\"))]\n",
        ")\n",
        "# gs_lr_tfidf = GridSearchCV(\n",
        "gs_lr_tfidf = TuneSearchCV(\n",
        "    lr_tfidf, param_grid, scoring=\"accuracy\", cv=5, verbose=2, n_jobs=-1,\n",
        "    early_stopping=True,\n",
        ")\n",
        "gs_lr_tfidf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-adjustment",
      "metadata": {
        "id": "found-adjustment"
      },
      "outputs": [],
      "source": [
        "print(f\"Best parameter set: {gs_lr_tfidf.best_params_}\")\n",
        "print(f\"CV Accuracy: {gs_lr_tfidf.best_score_:.3f}\")\n",
        "\n",
        "clf = gs_lr_tfidf.best_estimator_\n",
        "print(\"Test Accuracy: {0:.3f}\".format(clf.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "built-bargain",
      "metadata": {
        "id": "built-bargain"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "if not os.path.isfile(\"movie_data.csv\"):\n",
        "    if not os.path.isfile(\"movie_data.csv.zip\"):\n",
        "        print(\n",
        "            \"Please place a copy of the movie_data.csv.gz\"\n",
        "            \"in this directory. You can obtain it by\"\n",
        "            \"a) executing the code in the beginning of this\"\n",
        "            \"notebook or b) by downloading it from GitHub:\"\n",
        "            \"https://github.com/rasbt/python-machine-learning-\"\n",
        "            \"book-2nd-edition/blob/master/code/ch08/movie_data.csv.gz\"\n",
        "        )\n",
        "    else:\n",
        "        with zipfile.ZipFile(\"movie_data.csv.zip\", \"r\") as zip_ref:\n",
        "            zip_ref.extractall(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "removable-trainer",
      "metadata": {
        "id": "removable-trainer"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
        "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
        "    text = re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "associate-asset",
      "metadata": {
        "id": "associate-asset"
      },
      "outputs": [],
      "source": [
        "def stream_docs(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as csv:\n",
        "        next(csv)  # Skip header\n",
        "        for line in csv:\n",
        "            text, label = line[:-3], int(line[-2])\n",
        "            yield text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "separate-distribution",
      "metadata": {
        "id": "separate-distribution",
        "outputId": "a2b78a8b-7a43-4b31-f257-5ddba027dba7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('\"My family and I normally do not watch local movies for the simple reason that they are poorly made, they lack the depth, and just not worth our time.<br /><br />The trailer of \"\"Nasaan ka man\"\" caught my attention, my daughter in law\\'s and daughter\\'s so we took time out to watch it this afternoon. The movie exceeded our expectations. The cinematography was very good, the story beautiful and the acting awesome. Jericho Rosales was really very good, so\\'s Claudine Barretto. The fact that I despised Diether Ocampo proves he was effective at his role. I have never been this touched, moved and affected by a local movie before. Imagine a cynic like me dabbing my eyes at the end of the movie? Congratulations to Star Cinema!! Way to go, Jericho and Claudine!!\"',\n",
              " 1)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(stream_docs(path=\"movie_data.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "experimental-integration",
      "metadata": {
        "id": "experimental-integration"
      },
      "outputs": [],
      "source": [
        "def get_minibatch(doc_stream, size):\n",
        "    docs, y = [], []\n",
        "    try:\n",
        "        for _ in range(size):\n",
        "            text, label = next(doc_stream)\n",
        "            docs.append(text)\n",
        "            y.append(label)\n",
        "    except StopIteration:\n",
        "        return None, None\n",
        "    return docs, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "attempted-nepal",
      "metadata": {
        "id": "attempted-nepal"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "vect = HashingVectorizer(\n",
        "    decode_error=\"ignore\", n_features=2 ** 21, preprocessor=None, tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "clf = SGDClassifier(loss=\"log\", random_state=1, max_iter=1)\n",
        "doc_stream = stream_docs(path=\"movie_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "selected-bernard",
      "metadata": {
        "id": "selected-bernard",
        "outputId": "5635f72e-53bf-4f1d-e2d2-4d120adbf944"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:30\n"
          ]
        }
      ],
      "source": [
        "import pyprind\n",
        "\n",
        "pbar = pyprind.ProgBar(45)\n",
        "classes = np.array([0, 1])\n",
        "for _ in range(45):\n",
        "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
        "    if not X_train:\n",
        "        break\n",
        "    X_train = vect.transform(X_train)\n",
        "    clf.partial_fit(X_train, y_train, classes=classes)\n",
        "    pbar.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "classified-track",
      "metadata": {
        "id": "classified-track",
        "outputId": "e3e7c3d4-acca-4e98-d3b4-cb0b684708ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.866\n"
          ]
        }
      ],
      "source": [
        "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
        "X_test = vect.transform(X_test)\n",
        "print(\"Accuracy: {0:.3f}\".format(clf.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "critical-steam",
      "metadata": {
        "id": "critical-steam"
      },
      "outputs": [],
      "source": [
        "clf = clf.partial_fit(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statutory-messenger",
      "metadata": {
        "id": "statutory-messenger"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(stop_words=\"english\", max_df=0.1, max_features=5000)\n",
        "X = count.fit_transform(df[\"review\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affiliated-stake",
      "metadata": {
        "id": "affiliated-stake"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(\n",
        "    n_components=10, random_state=123, learning_method=\"batch\"\n",
        ")\n",
        "X_topics = lda.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "split-visit",
      "metadata": {
        "id": "split-visit",
        "outputId": "7754f190-87b3-4092-a46e-9ddbe808fe47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 5000)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda.components_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "difficult-albania",
      "metadata": {
        "id": "difficult-albania",
        "outputId": "0b141a99-e93b-40a9-eba1-2daf67f64376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 1\n",
            "worst minutes awful script stupid\n",
            "Topic 2\n",
            "family mother father girl children\n",
            "Topic 3\n",
            "american dvd war music tv\n",
            "Topic 4\n",
            "human audience cinema art feel\n",
            "Topic 5\n",
            "police guy car dead murder\n",
            "Topic 6\n",
            "horror house gore blood sex\n",
            "Topic 7\n",
            "role performance comedy actor performances\n",
            "Topic 8\n",
            "series episode war episodes season\n",
            "Topic 9\n",
            "book version original effects read\n",
            "Topic 10\n",
            "action fight guy guys cool\n"
          ]
        }
      ],
      "source": [
        "n_top_words = 5\n",
        "feature_names = count.get_feature_names()\n",
        "\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(\"Topic {0}\".format(topic_idx + 1))\n",
        "    print(\n",
        "        \" \".join(\n",
        "            [feature_names[i] for i in topic.argsort()[: -n_top_words - 1 : -1]]\n",
        "        )  # Sort in reverse orders\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cardiac-preference",
      "metadata": {
        "id": "cardiac-preference",
        "outputId": "9e53ac55-95ec-4291-f18b-a0eb734afc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Horror movie #1\n",
            "Emilio Miraglia's first Giallo feature, The Night Evelyn Came Out of the Grave, was a great combination of Giallo and Gothic horror - and this second film is even better! We've got more of the Giallo side of the equation this time around, although Miraglia doesn't lose the Gothic horror stylings tha ...\n",
            "Horror movie #2\n",
            "House of Dracula works from the same basic premise as House of Frankenstein from the year before; namely that Universal's three most famous monsters; Dracula, Frankenstein's Monster and The Wolf Man are appearing in the movie together. Naturally, the film is rather messy therefore, but the fact that ...\n",
            "Horror movie #3\n",
            "This film marked the end of the \"serious\" Universal Monsters era (Abbott and Costello meet up with the monsters later in \"Abbott and Costello Meet Frankentstein\"). It was a somewhat desparate, yet fun attempt to revive the classic monsters of the Wolf Man, Frankenstein's monster, and Dracula one \"la ...\n"
          ]
        }
      ],
      "source": [
        "horror = X_topics[:, 5].argsort()[::-1]\n",
        "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
        "    print(\"Horror movie #{0}\".format(iter_idx + 1))\n",
        "    print(df[\"review\"][movie_idx][:300], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "temporal-jordan",
      "metadata": {
        "id": "temporal-jordan"
      },
      "source": [
        "# Serializing fitted scikit-learn estimators\n",
        "\n",
        "- training machine learning is computationally expensive\n",
        "- pickled allow us to serialize/deserialize Python object structures to compact bytecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "casual-appliance",
      "metadata": {
        "id": "casual-appliance"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "dest = os.path.join(\"movieclassifier\", \"pkl_objects\")\n",
        "if not os.path.exists(dest):\n",
        "    os.makedirs(dest)\n",
        "\n",
        "\n",
        "pickle.dump(stop, open(os.path.join(dest, \"stopwords.pkl\"), \"wb\"), protocol=4)\n",
        "pickle.dump(clf, open(os.path.join(dest, \"classifier.pkl\"), \"wb\"), protocol=4)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "colab": {
      "name": "08_sentiment_analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
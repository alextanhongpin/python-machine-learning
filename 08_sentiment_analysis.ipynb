{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alextanhongpin/python-machine-learning/blob/master/08_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "static-slide",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "static-slide",
        "outputId": "e3471dfd-b951-49f9-bec4-ca2e6fe1624f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  48.5M      0  0:00:01  0:00:01 --:--:-- 48.5M\n"
          ]
        }
      ],
      "source": [
        "# https://ai.stanford.edu/~amaas/data/sentiment/\n",
        "!curl https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz -o aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "impossible-glass",
      "metadata": {
        "id": "impossible-glass"
      },
      "outputs": [],
      "source": [
        "!tar -zxf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "grave-migration",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grave-migration",
        "outputId": "7e296b38-5dd0-4152-d07a-97de0a09f460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.7/dist-packages (2.11.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyprind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "canadian-broadcasting",
      "metadata": {
        "id": "canadian-broadcasting"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import pyprind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "included-tonight",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "included-tonight",
        "outputId": "75afe73b-4ea3-40bc-8a64-6df10e60ef64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:29\n"
          ]
        }
      ],
      "source": [
        "basepath = \"aclImdb\"\n",
        "\n",
        "labels = {\"pos\": 1, \"neg\": 0}\n",
        "pbar = pyprind.ProgBar(50000)\n",
        "df = pd.DataFrame()\n",
        "\n",
        "for s in (\"test\", \"train\"):\n",
        "    for l in (\"pos\", \"neg\"):\n",
        "        path = os.path.join(basepath, s, l)\n",
        "        for file in os.listdir(path):\n",
        "            with open(os.path.join(path, file), \"r\", encoding=\"utf-8\") as infile:\n",
        "                txt = infile.read()\n",
        "            df = df.append([[txt, labels[l]]], ignore_index=True)\n",
        "            pbar.update()\n",
        "df.columns = [\"review\", \"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "seasonal-threat",
      "metadata": {
        "id": "seasonal-threat"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv(\"movie_data.csv\", index=False, encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bigger-toolbox",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bigger-toolbox",
        "outputId": "34f902d4-562e-4e05-9dff-d5de1868bb27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9fbed4eb-2bfd-47f2-8387-22fff060e675\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I loved the movie \"Northfork\". I knew nothing ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>publicity got me to the theatre&lt;br /&gt;&lt;br /&gt;adv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I will never forget the night I saw this movie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fbed4eb-2bfd-47f2-8387-22fff060e675')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9fbed4eb-2bfd-47f2-8387-22fff060e675 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9fbed4eb-2bfd-47f2-8387-22fff060e675');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  I loved the movie \"Northfork\". I knew nothing ...          1\n",
              "1  publicity got me to the theatre<br /><br />adv...          0\n",
              "2  I will never forget the night I saw this movie...          0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv(\"movie_data.csv\", encoding=\"utf-8\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "reasonable-delight",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reasonable-delight",
        "outputId": "f87ce1e2-1960-4805-b216-1b774932e50a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 0, 0, 1, 1, 1],\n",
              "       [1, 2, 1, 1, 1, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "docs = np.array(\n",
        "    [\n",
        "        \"The sun is shining\",\n",
        "        \"The weather is sweet\",\n",
        "        \"The sun is shining and the weather is sweet\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "bag = count.fit_transform(docs)\n",
        "bag.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "protecting-evening",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "protecting-evening",
        "outputId": "65a1dc0b-b4db-4792-ec2f-b1c039a3b24a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 0, 'is': 1, 'shining': 2, 'sun': 3, 'sweet': 4, 'the': 5, 'weather': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "count.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "apparent-shell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apparent-shell",
        "outputId": "96501d77-ded6-4f43-fe18-4265289cbb53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.43, 0.56, 0.56, 0.  , 0.43, 0.  ],\n",
              "       [0.  , 0.43, 0.  , 0.  , 0.56, 0.43, 0.56],\n",
              "       [0.4 , 0.48, 0.31, 0.31, 0.31, 0.48, 0.31]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf = TfidfTransformer(use_idf=True, norm=\"l2\", smooth_idf=True)\n",
        "np.set_printoptions(precision=2)\n",
        "tfidf.fit_transform(count.fit_transform(docs)).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "charming-tuesday",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "charming-tuesday",
        "outputId": "bb2c2f73-c0a5-42ae-c3ad-24e47468b55c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' watch it again... I know I will.<br /><br />Terry'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.loc[0, \"review\"][-50:]  # Print last 50 characters from the review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "extensive-webmaster",
      "metadata": {
        "id": "extensive-webmaster"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def preprocessor(text):\n",
        "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
        "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
        "    text = re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "directed-assessment",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "directed-assessment",
        "outputId": "4549999c-6114-411f-a546-fe34f04d8175"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is a test :) :( :)'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "preprocessor(\"</a>This :) is :( a test :-)!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "strange-rochester",
      "metadata": {
        "id": "strange-rochester"
      },
      "outputs": [],
      "source": [
        "df.review = df.review.apply(preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "plastic-karma",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plastic-karma",
        "outputId": "fc6ae085-ffef-445b-fe2c-218afbaf88c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "tokenizer(\"runners like running and thus they run\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "single-charger",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "single-charger",
        "outputId": "061c8a09-b5b0-4936-82bb-8205a0e5cb3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "\n",
        "\n",
        "tokenizer_porter(\"runners like running and thus they run\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "composed-toilet",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "composed-toilet",
        "outputId": "50d097b9-0609-40e9-ce05-afc0793b231c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "subjective-mattress",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "subjective-mattress",
        "outputId": "ed793f87-cefc-46c4-a3a9-54cb8aa360b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'runnign', 'run', 'lot']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "[\n",
        "    w\n",
        "    for w in tokenizer_porter(\"a runner likes runnign and runs a lot\")[-10:]\n",
        "    if w not in stop\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "characteristic-uniform",
      "metadata": {
        "id": "characteristic-uniform"
      },
      "source": [
        "# Training a logistic regression model for document classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "active-flood",
      "metadata": {
        "id": "active-flood"
      },
      "outputs": [],
      "source": [
        "X_train = df.loc[:25000, \"review\"].values\n",
        "y_train = df.loc[:25000, \"sentiment\"].values\n",
        "\n",
        "X_test = df.loc[25000:, \"review\"].values\n",
        "y_test = df.loc[25000:, \"sentiment\"].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tune_sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE5Z2vg_spva",
        "outputId": "e8efb36c-7a01-4762-c080-b382c60c0315"
      },
      "id": "WE5Z2vg_spva",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tune_sklearn\n",
            "  Downloading tune_sklearn-0.4.1-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting ray[tune]\n",
            "  Downloading ray-1.10.0-cp37-cp37m-manylinux2014_x86_64.whl (59.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.6 MB 47 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from tune_sklearn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from tune_sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from tune_sklearn) (1.4.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (7.1.2)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (1.43.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (21.4.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (1.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (3.13)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.1.3-py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (3.4.2)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]->tune_sklearn) (0.8.9)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray[tune]->tune_sklearn) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]->tune_sklearn) (4.10.1)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]->tune_sklearn) (21.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]->tune_sklearn) (1.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]->tune_sklearn) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]->tune_sklearn) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]->tune_sklearn) (3.0.7)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]->tune_sklearn) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]->tune_sklearn) (0.18.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]->tune_sklearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]->tune_sklearn) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune_sklearn) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune_sklearn) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune_sklearn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]->tune_sklearn) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tune_sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->tune_sklearn) (1.1.0)\n",
            "Installing collected packages: deprecated, redis, tensorboardX, ray, tune-sklearn\n",
            "Successfully installed deprecated-1.2.13 ray-1.10.0 redis-4.1.3 tensorboardX-2.4.1 tune-sklearn-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/5x-faster-scikit-learn-parameter-tuning-in-5-lines-of-code-be6bdd21833c\n",
        "from tune_sklearn import TuneGridSearchCV"
      ],
      "metadata": {
        "id": "VBIjDt_4sv1C"
      },
      "id": "VBIjDt_4sv1C",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tutorial-testimony",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tutorial-testimony",
        "outputId": "0950712e-22ef-4d4b-cb0f-541d887008da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ray/tune/tune.py:376: UserWarning: The `loggers` argument is deprecated. Please pass the respective `LoggerCallback` classes to the `callbacks` argument instead. See https://docs.ray.io/en/latest/tune/api_docs/logging.html\n",
            "  \"The `loggers` argument is deprecated. Please pass the respective \"\n",
            "save not implemented for Searcher. Skipping save.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:35:25 (running for 00:00:02.35)<br>Memory usage on this node: 1.8/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 1/48 (1 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:35:29 (running for 00:00:06.56)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=469)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', \"it'\", 'onc', 'onli', 'ourselv', \"she'\", \"should'v\", 'themselv', 'thi', 'veri', 'wa', 'whi', \"you'r\", \"you'v\", 'yourselv'] not in stop_words.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=469)\u001b[0m   % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:35:33 (running for 00:00:10.38)<br>Memory usage on this node: 2.0/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:35:38 (running for 00:00:15.46)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:35:43 (running for 00:00:20.50)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:35:48 (running for 00:00:25.52)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:35:53 (running for 00:00:30.55)<br>Memory usage on this node: 2.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:35:58 (running for 00:00:35.58)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial _PipelineTrainable_c627b7dc reported average_test_score=0.88 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f076328e5f0>}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:04 (running for 00:00:41.44)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae9e0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:09 (running for 00:00:46.47)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae9e0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:14 (running for 00:00:51.50)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae9e0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:19 (running for 00:00:56.53)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae9e0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial _PipelineTrainable_c627b7dc reported average_test_score=0.88 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f076328e5f0>}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:25 (running for 00:01:02.34)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae5f0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:30 (running for 00:01:07.37)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae5f0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:35 (running for 00:01:12.40)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae5f0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:40 (running for 00:01:17.42)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae5f0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2022-02-12 16:36:45 (running for 00:01:22.44)<br>Memory usage on this node: 2.2/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 4.000: None | Iter 1.000: 0.8760847430513898<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.87 GiB heap, 0.0/3.44 GiB objects<br>Current best trial: c627b7dc with average_test_score=0.8760847430513898 and parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f056c1ae5f0>}<br>Result logdir: /root/ray_results/_PipelineTrainable_2022-02-12_16-35-16<br>Number of trials: 3/48 (1 PENDING, 2 RUNNING)<br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m /usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "\u001b[2m\u001b[36m(_PipelineTrainable pid=468)\u001b[0m   ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial _PipelineTrainable_c627b7dc reported average_test_score=0.88 with parameters={'early_stopping': True, 'early_stop_type': <EarlyStopping.WARM_START_ITER: 2>, 'X_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000001000000), 'y_id': ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000002000000), 'groups': None, 'cv': StratifiedKFold(n_splits=5, random_state=None, shuffle=False), 'fit_params': {}, 'scoring': {'score': make_scorer(accuracy_score)}, 'max_iters': 10, 'return_train_score': False, 'n_jobs': 1, 'metric_name': 'average_test_score', 'estimator_ids': [ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000003000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000004000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000005000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000006000000), ObjectRef(ffffffffffffffffffffffffffffffffffffffff0100000007000000)], 'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vect__tokenizer': <function tokenizer at 0x7f076328e5f0>}.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
        "param_grid = [\n",
        "    {\n",
        "        \"vect__ngram_range\": [(1, 1)],\n",
        "        \"vect__stop_words\": [stop, None],\n",
        "        \"vect__tokenizer\": [tokenizer, tokenizer_porter],\n",
        "        \"clf__penalty\": [\"l1\", \"l2\"],\n",
        "        \"clf__C\": [1.0, 10.0, 100.0],\n",
        "    },\n",
        "    {\n",
        "        \"vect__ngram_range\": [(1, 1)],\n",
        "        \"vect__stop_words\": [stop, None],\n",
        "        \"vect__tokenizer\": [tokenizer, tokenizer_porter],\n",
        "        \"vect__use_idf\": [False],\n",
        "        \"vect__norm\": [None],\n",
        "        \"clf__penalty\": [\"l1\", \"l2\"],\n",
        "        \"clf__C\": [1.0, 10.0, 100.0],\n",
        "    },\n",
        "]\n",
        "\n",
        "lr_tfidf = Pipeline(\n",
        "    [(\"vect\", tfidf), (\"clf\", LogisticRegression(random_state=0, solver=\"liblinear\"))]\n",
        ")\n",
        "# gs_lr_tfidf = GridSearchCV(\n",
        "gs_lr_tfidf = TuneGridSearchCV(\n",
        "    lr_tfidf, param_grid, scoring=\"accuracy\", cv=5, verbose=2, n_jobs=-1,\n",
        "    # Two new parameters.\n",
        "    early_stopping=True,\n",
        "    max_iters=10\n",
        ")\n",
        "gs_lr_tfidf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-adjustment",
      "metadata": {
        "id": "found-adjustment"
      },
      "outputs": [],
      "source": [
        "print(f\"Best parameter set: {gs_lr_tfidf.best_params_}\")\n",
        "print(f\"CV Accuracy: {gs_lr_tfidf.best_score_:.3f}\")\n",
        "\n",
        "clf = gs_lr_tfidf.best_estimator_\n",
        "print(\"Test Accuracy: {0:.3f}\".format(clf.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "built-bargain",
      "metadata": {
        "id": "built-bargain"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "if not os.path.isfile(\"movie_data.csv\"):\n",
        "    if not os.path.isfile(\"movie_data.csv.zip\"):\n",
        "        print(\n",
        "            \"Please place a copy of the movie_data.csv.gz\"\n",
        "            \"in this directory. You can obtain it by\"\n",
        "            \"a) executing the code in the beginning of this\"\n",
        "            \"notebook or b) by downloading it from GitHub:\"\n",
        "            \"https://github.com/rasbt/python-machine-learning-\"\n",
        "            \"book-2nd-edition/blob/master/code/ch08/movie_data.csv.gz\"\n",
        "        )\n",
        "    else:\n",
        "        with zipfile.ZipFile(\"movie_data.csv.zip\", \"r\") as zip_ref:\n",
        "            zip_ref.extractall(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "removable-trainer",
      "metadata": {
        "id": "removable-trainer"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words(\"english\")\n",
        "\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
        "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
        "    text = re.sub(\"[\\W]+\", \" \", text.lower()) + \" \".join(emoticons).replace(\"-\", \"\")\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "associate-asset",
      "metadata": {
        "id": "associate-asset"
      },
      "outputs": [],
      "source": [
        "def stream_docs(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as csv:\n",
        "        next(csv)  # Skip header\n",
        "        for line in csv:\n",
        "            text, label = line[:-3], int(line[-2])\n",
        "            yield text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "separate-distribution",
      "metadata": {
        "id": "separate-distribution"
      },
      "outputs": [],
      "source": [
        "next(stream_docs(path=\"movie_data.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "experimental-integration",
      "metadata": {
        "id": "experimental-integration"
      },
      "outputs": [],
      "source": [
        "def get_minibatch(doc_stream, size):\n",
        "    docs, y = [], []\n",
        "    try:\n",
        "        for _ in range(size):\n",
        "            text, label = next(doc_stream)\n",
        "            docs.append(text)\n",
        "            y.append(label)\n",
        "    except StopIteration:\n",
        "        return None, None\n",
        "    return docs, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "attempted-nepal",
      "metadata": {
        "id": "attempted-nepal"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "vect = HashingVectorizer(\n",
        "    decode_error=\"ignore\", n_features=2 ** 21, preprocessor=None, tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "clf = SGDClassifier(loss=\"log\", random_state=1, max_iter=1)\n",
        "doc_stream = stream_docs(path=\"movie_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "selected-bernard",
      "metadata": {
        "id": "selected-bernard"
      },
      "outputs": [],
      "source": [
        "import pyprind\n",
        "\n",
        "pbar = pyprind.ProgBar(45)\n",
        "classes = np.array([0, 1])\n",
        "for _ in range(45):\n",
        "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
        "    if not X_train:\n",
        "        break\n",
        "    X_train = vect.transform(X_train)\n",
        "    clf.partial_fit(X_train, y_train, classes=classes)\n",
        "    pbar.update()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "classified-track",
      "metadata": {
        "id": "classified-track"
      },
      "outputs": [],
      "source": [
        "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
        "X_test = vect.transform(X_test)\n",
        "print(\"Accuracy: {0:.3f}\".format(clf.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "critical-steam",
      "metadata": {
        "id": "critical-steam"
      },
      "outputs": [],
      "source": [
        "clf = clf.partial_fit(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "statutory-messenger",
      "metadata": {
        "id": "statutory-messenger"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer(stop_words=\"english\", max_df=0.1, max_features=5000)\n",
        "X = count.fit_transform(df[\"review\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affiliated-stake",
      "metadata": {
        "id": "affiliated-stake"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda = LatentDirichletAllocation(\n",
        "    n_components=10, random_state=123, learning_method=\"batch\"\n",
        ")\n",
        "X_topics = lda.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "split-visit",
      "metadata": {
        "id": "split-visit"
      },
      "outputs": [],
      "source": [
        "lda.components_.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "difficult-albania",
      "metadata": {
        "id": "difficult-albania"
      },
      "outputs": [],
      "source": [
        "n_top_words = 5\n",
        "feature_names = count.get_feature_names()\n",
        "\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(\"Topic {0}\".format(topic_idx + 1))\n",
        "    print(\n",
        "        \" \".join(\n",
        "            [feature_names[i] for i in topic.argsort()[: -n_top_words - 1 : -1]]\n",
        "        )  # Sort in reverse orders\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cardiac-preference",
      "metadata": {
        "id": "cardiac-preference"
      },
      "outputs": [],
      "source": [
        "horror = X_topics[:, 5].argsort()[::-1]\n",
        "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
        "    print(\"Horror movie #{0}\".format(iter_idx + 1))\n",
        "    print(df[\"review\"][movie_idx][:300], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "temporal-jordan",
      "metadata": {
        "id": "temporal-jordan"
      },
      "source": [
        "# Serializing fitted scikit-learn estimators\n",
        "\n",
        "- training machine learning is computationally expensive\n",
        "- pickled allow us to serialize/deserialize Python object structures to compact bytecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "casual-appliance",
      "metadata": {
        "id": "casual-appliance"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "dest = os.path.join(\"movieclassifier\", \"pkl_objects\")\n",
        "if not os.path.exists(dest):\n",
        "    os.makedirs(dest)\n",
        "\n",
        "\n",
        "pickle.dump(stop, open(os.path.join(dest, \"stopwords.pkl\"), \"wb\"), protocol=4)\n",
        "pickle.dump(clf, open(os.path.join(dest, \"classifier.pkl\"), \"wb\"), protocol=4)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "colab": {
      "name": "08_sentiment_analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}